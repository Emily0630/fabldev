u <- c(.99, .01, .99, .01,
1 - 1/30, 1/30, 1 - 1/12, 1/12, 1 - 1/15, 1/15)
levels <- c(2, 2, 2, 2, 2)
S <- 50; burn <- S * .1
m_prior <- u_prior <- rep(1, length(m))
alpha <- beta <- 1
cd <- simulate_comparisons(m, u, levels, n1, n2, overlap)
hash <- hash_comparisons(cd)
Ztrue <- cd$Ztrue
out <- svi_efficient(hash, B = 10, k = 1, seed = 42)
results <- vi_estimate_links(out, hash)
evaluate_links(results$Z_hat, Z_true, n1)
out$t
evaluate_links(results$Z_hat, Ztrue, n1)
out <- vi_efficient(hash)
results <- vi_estimate_links(out, hash)
evaluate_links(results$Z_hat, Ztrue, n1)
out$t
out <- svi_efficient(hash, B = 10, k = 1, seed = 42)
results <- vi_estimate_links(out, hash)
evaluate_links(results$Z_hat, Ztrue, n1)
out$t
out <- svi_efficient(hash, B = 10, k = 1, seed = 5)
results <- vi_estimate_links(out, hash)
evaluate_links(results$Z_hat, Ztrue, n1)
out$t
out <- svi_efficient(hash, B = 20, k = 1, seed = 5)
results <- vi_estimate_links(out, hash)
evaluate_links(results$Z_hat, Ztrue, n1)
out$t
out <- svi_efficient(hash, B = 30, k = 1, seed = 5)
evaluate_links(results$Z_hat, Ztrue, n1)
out$t
out <- svi_efficient(hash, B = 50, k = 1, seed = 5)
results <- vi_estimate_links(out, hash)
evaluate_links(results$Z_hat, Ztrue, n1)
out$t
out <- svi_efficient(hash, B = 10, k = 1, seed = 5)
results <- vi_estimate_links(out, hash)
evaluate_links(results$Z_hat, Ztrue, n1)
out$t
out$elbo_seq
out$elbo_seq
out <- svi_efficient(hash, B = 10, k = .5, seed = 5)
results <- vi_estimate_links(out, hash)
evaluate_links(results$Z_hat, Ztrue, n1)
out$t
out <- svi_efficient(hash, B = 10, k = 1, seed = 5)
results <- vi_estimate_links(out, hash)
evaluate_links(results$Z_hat, Ztrue, n1)
out$t
i = 1
ohe <- hash$ohe # One-hot encodings e(h_p)
P <- dim(ohe)[1]
total_counts <- hash$total_counts #N_p
# pattern_counts_by_record <- hash$pattern_counts_by_record #N_p_j
# record_counts_by_pattern <- hash$record_counts_by_pattern
hash_count_list <- hash$hash_count_list
field_marker <- hash$field_marker
n1 <- hash$n1
n2 <- hash$n2
# Priors
alpha <- rep(1, length(field_marker))
Beta <- rep(1, length(field_marker))
alpha_pi <- 1
beta_pi <- 1
# Initialize
a <- rep(1, length(field_marker))
if(b_init == T){
b <- hash$ohe %>%
sweep(., 1, hash$total_counts, "*") %>%
colSums()
} else {
b = rep(1, length(field_marker))
}
a_pi <- 1
b_pi <- 1
t <- 1
ratio <- 1
elbo_seq <- vector()
adjustment <- n2 / B
B = 10
adjustment <- n2 / B
n2
a_sum <- a %>%
split(., field_marker) %>%
sapply(., sum) %>%
digamma(.) %>%
.[field_marker]
a_chunk <- digamma(a) - a_sum
b_sum <- b %>%
split(., field_marker) %>%
sapply(., sum) %>%
digamma(.) %>%
.[field_marker]
b_chunk <- digamma(b) - b_sum
m_p <- ohe %>%
sweep(., 2, a_chunk, "*") %>%
rowSums()
u_p <- ohe %>%
sweep(., 2, b_chunk, "*") %>%
rowSums()
# w_p
weights = m_p - u_p
# phi_single
phi <- exp(digamma(a_pi) - digamma(n1) + weights)
single <- exp(digamma(b_pi))
# Phi_j
batch <- sample(1:n2, B, replace = F)
C <- sapply(batch, function(j){
hash_count_list[[j]] %*% phi + single
})
batch
C
# S(Phi, B)
total_nonmatch <- adjustment * sum(single/ C)
hash_count_list[[batch[i]]]
hash_count_list[[batch[i]]] / C[i]
K <- sapply(seq_along(batch), function(i){
hash_count_list[[batch[i]]] / C[i]
}) %>%
rowSums() * adjustment
K
sum(K)
sapply(seq_along(batch), function(i){
hash_count_list[[batch[i]]] / C[i]
})
C
C <- sapply(hash_count_list, function(x){
x %*% phi + single
})
# S(Phi)
total_nonmatch <- sum(single/ C)
# N_p(Psi)
# K <- apply(hash_count_table, 1, function(x){
#   sum(x/C)
# })
K <- sapply(1:n2, function(j){
hash_count_list[[j]] / C[j]
}) %>%
rowSums()
K
C <- sapply(batch, function(j){
hash_count_list[[j]] %*% phi + single
})
# S(Phi, B)
total_nonmatch <- adjustment * sum(single/ C)
K <- sapply(seq_along(batch), function(i){
hash_count_list[[batch[i]]] / C[i]
}) %>%
rowSums() * adjustment
K
threshold = 1e-6
tmax = 1000
fixed_iterations = NULL
b_init = TRUE
check_every = 10
store_every = check_every
df1 <- read.csv("../vablpaper/data/febrl_4_A.csv") %>%
arrange(rec_id) %>%
mutate(rec_id = row_number()) %>%
filter(rec_id <= 10)
df2 <- read.csv("../vablpaper/data/febrl_4_B.csv") %>%
arrange(rec_id) %>%
mutate(rec_id = row_number()) %>%
filter(rec_id <= 10)
batch_1 <- 1:5
batch_2 <- 6:10
n1 <- nrow(df1)
n2 <- nrow(df2)
Z_true <- seq(1:10)
fields <- c(2, 3, 8, 10, 11)
types <- c("lv", "lv","bi", "bi", "bi")
cd_1 <- compare_records(df1, df2[batch_1, ], flds = fields, types = types,
breaks = c(0, .15))
hash_1 <- hash_comparisons(cd_1, all_patterns = T)
cd_2 <- compare_records(df1, df2[batch_2, ], flds = fields, types = types,
breaks = c(0, .15))
hash_2 <- hash_comparisons(cd_2, all_patterns = T)
hash_list <- list(hash_1, hash_2)
hash <- combine_hash(hash_list = hash_list, n1, n2)
out <- vi_efficient(hash)
View(hash)
devtools::load_all(".")
threshold = 1e-6
tmax = 1000
fixed_iterations = NULL
b_init = TRUE
check_every = 10
store_every = check_every
df1 <- read.csv("../vablpaper/data/febrl_4_A.csv") %>%
arrange(rec_id) %>%
mutate(rec_id = row_number()) %>%
filter(rec_id <= 10)
df2 <- read.csv("../vablpaper/data/febrl_4_B.csv") %>%
arrange(rec_id) %>%
mutate(rec_id = row_number()) %>%
filter(rec_id <= 10)
batch_1 <- 1:5
batch_2 <- 6:10
n1 <- nrow(df1)
n2 <- nrow(df2)
Z_true <- seq(1:10)
fields <- c(2, 3, 8, 10, 11)
types <- c("lv", "lv","bi", "bi", "bi")
cd_1 <- compare_records(df1, df2[batch_1, ], flds = fields, types = types,
breaks = c(0, .15))
hash_1 <- hash_comparisons(cd_1, all_patterns = T)
cd_2 <- compare_records(df1, df2[batch_2, ], flds = fields, types = types,
breaks = c(0, .15))
hash_2 <- hash_comparisons(cd_2, all_patterns = T)
hash_list <- list(hash_1, hash_2)
hash <- combine_hash(hash_list = hash_list, n1, n2)
out <- vi_efficient(hash)
View(hash)
warnings()
purrr::map(hash_list, ~.x$total_counts) %>%
do.call(rbind, .)
hash_1$total_counts
cd_1 <- compare_records(df1, df2[batch_1, ], flds = fields, types = types,
breaks = c(0, .15))
hash_1 <- hash_comparisons(cd_1, all_patterns = T)
View(hash_1)
indicators <- cd[[1]]
N <- dim(indicators)[1]
n1 <- cd[[2]]
n2 <- cd[[3]]
levels <- cd[[4]]
fields <- seq_along(cd[[4]])
field_marker <- sapply(fields, function(x){
rep(x, cd[[4]][x])
}) %>%
unlist(.) %>%
as.vector(.)
ids <- expand.grid(1:n1, 1:n2)
rec1 <- ids[,1]
rec2 <- ids[,2]
Lf_vec<- (levels) %>%
c(0, .) %>%
cumsum()
hash_vals <- purrr::imap(cd[[4]], ~hash_field(.x, .y, Lf_vec)) %>%
unlist()
hash <- sweep(indicators, 2, hash_vals, "*") %>%
rowSums() + 1
if(all_patterns == TRUE){
unique_patterns <- possible_patterns_sadinle(levels)
unique_hashed <- sweep(unique_patterns, 2, hash_vals, "*") %>%
rowSums() + 1
P <- dim(unique_patterns)[1]
hash_id <- match(hash, unique_hashed) %>%
factor(levels = 1:P)
} else {
unique_hashed <- unique(hash)
P <- length(unique_hashed)
hash_id <- match(hash, unique_hashed) %>%
factor(levels = 1:P)
unique_patterns <- indicators[!duplicated(hash_id), ]
}
temp <- data.frame(rec1, rec2, hash_id)
hash_count_list <- temp %>%
group_by(rec2, hash_id, .drop = F) %>%
count() %>%
ungroup() %>%
group_split(rec2) %>%
purrr::map(~.x %>%
select(n) %>%
pull()
)
#total_counts <- rowSums(hash_count_list)
total_counts <- temp %>%
group_by(hash_id) %>%
count() %>%
pull()
cd <- cd_1
indicators <- cd[[1]]
N <- dim(indicators)[1]
n1 <- cd[[2]]
n2 <- cd[[3]]
levels <- cd[[4]]
fields <- seq_along(cd[[4]])
field_marker <- sapply(fields, function(x){
rep(x, cd[[4]][x])
}) %>%
unlist(.) %>%
as.vector(.)
ids <- expand.grid(1:n1, 1:n2)
rec1 <- ids[,1]
rec2 <- ids[,2]
Lf_vec<- (levels) %>%
c(0, .) %>%
cumsum()
hash_vals <- purrr::imap(cd[[4]], ~hash_field(.x, .y, Lf_vec)) %>%
unlist()
hash <- sweep(indicators, 2, hash_vals, "*") %>%
rowSums() + 1
if(all_patterns == TRUE){
unique_patterns <- possible_patterns_sadinle(levels)
unique_hashed <- sweep(unique_patterns, 2, hash_vals, "*") %>%
rowSums() + 1
P <- dim(unique_patterns)[1]
hash_id <- match(hash, unique_hashed) %>%
factor(levels = 1:P)
} else {
unique_hashed <- unique(hash)
P <- length(unique_hashed)
hash_id <- match(hash, unique_hashed) %>%
factor(levels = 1:P)
unique_patterns <- indicators[!duplicated(hash_id), ]
}
temp <- data.frame(rec1, rec2, hash_id)
levels
all_patterns
all_patterns = TRUE
if(all_patterns == TRUE){
unique_patterns <- possible_patterns_sadinle(levels)
unique_hashed <- sweep(unique_patterns, 2, hash_vals, "*") %>%
rowSums() + 1
P <- dim(unique_patterns)[1]
hash_id <- match(hash, unique_hashed) %>%
factor(levels = 1:P)
} else {
unique_hashed <- unique(hash)
P <- length(unique_hashed)
hash_id <- match(hash, unique_hashed) %>%
factor(levels = 1:P)
unique_patterns <- indicators[!duplicated(hash_id), ]
}
temp <- data.frame(rec1, rec2, hash_id)
hash_count_list <- temp %>%
group_by(rec2, hash_id, .drop = F) %>%
count() %>%
ungroup() %>%
group_split(rec2) %>%
purrr::map(~.x %>%
select(n) %>%
pull()
)
#total_counts <- rowSums(hash_count_list)
total_counts <- temp %>%
group_by(hash_id) %>%
count() %>%
pull()
pattern_lookup <- expand.grid(1:P, 1:n2) %>%
data.frame() %>%
setNames(., c("hash_id", "rec2"))
threshold = 1e-6
tmax = 1000
fixed_iterations = NULL
b_init = TRUE
check_every = 10
store_every = check_every
all_patterns = TRUE
df1 <- read.csv("../vablpaper/data/febrl_4_A.csv") %>%
arrange(rec_id) %>%
mutate(rec_id = row_number()) %>%
filter(rec_id <= 10)
df2 <- read.csv("../vablpaper/data/febrl_4_B.csv") %>%
arrange(rec_id) %>%
mutate(rec_id = row_number()) %>%
filter(rec_id <= 10)
batch_1 <- 1:5
batch_2 <- 6:10
n1 <- nrow(df1)
n2 <- nrow(df2)
Z_true <- seq(1:10)
fields <- c(2, 3, 8, 10, 11)
types <- c("lv", "lv","bi", "bi", "bi")
cd_1 <- compare_records(df1, df2[batch_1, ], flds = fields, types = types,
breaks = c(0, .15))
hash_1 <- hash_comparisons(cd_1, all_patterns = T)
cd_2 <- compare_records(df1, df2[batch_2, ], flds = fields, types = types,
breaks = c(0, .15))
hash_2 <- hash_comparisons(cd_2, all_patterns = T)
hash_list <- list(hash_1, hash_2)
hash <- combine_hash(hash_list = hash_list, n1, n2)
View(hash_1)
devtools::load_all(".")
cd <- cd_1
indicators <- cd[[1]]
N <- dim(indicators)[1]
n1 <- cd[[2]]
n2 <- cd[[3]]
levels <- cd[[4]]
fields <- seq_along(cd[[4]])
field_marker <- sapply(fields, function(x){
rep(x, cd[[4]][x])
}) %>%
unlist(.) %>%
as.vector(.)
ids <- expand.grid(1:n1, 1:n2)
rec1 <- ids[,1]
rec2 <- ids[,2]
Lf_vec<- (levels) %>%
c(0, .) %>%
cumsum()
hash_vals <- purrr::imap(cd[[4]], ~hash_field(.x, .y, Lf_vec)) %>%
unlist()
hash <- sweep(indicators, 2, hash_vals, "*") %>%
rowSums() + 1
if(all_patterns == TRUE){
unique_patterns <- possible_patterns_sadinle(levels)
unique_hashed <- sweep(unique_patterns, 2, hash_vals, "*") %>%
rowSums() + 1
P <- dim(unique_patterns)[1]
hash_id <- match(hash, unique_hashed) %>%
factor(levels = 1:P)
} else {
unique_hashed <- unique(hash)
P <- length(unique_hashed)
hash_id <- match(hash, unique_hashed) %>%
factor(levels = 1:P)
unique_patterns <- indicators[!duplicated(hash_id), ]
}
temp <- data.frame(rec1, rec2, hash_id)
hash_count_list <- temp %>%
group_by(rec2, hash_id, .drop = F) %>%
count() %>%
ungroup() %>%
group_split(rec2) %>%
purrr::map(~.x %>%
select(n) %>%
pull()
)
#total_counts <- rowSums(hash_count_list)
total_counts <- temp %>%
group_by(hash_id) %>%
count() %>%
pull()
pattern_lookup <- expand.grid(1:P, 1:n2) %>%
data.frame() %>%
setNames(., c("hash_id", "rec2"))
pair_to_pattern <- NULL
hash_to_file_1 <- temp %>%
select(rec1, rec2, hash_id) %>%
nest_by(rec2, hash_id, .keep = F) %>%
mutate(hash_id = as.integer(hash_id)) %>%
rowwise() %>%
mutate(N = nrow(data))
hash_to_file_1 <- left_join(x = pattern_lookup,
y = hash_to_file_1,
by = c("hash_id", "rec2"))
hash_to_file_1$N[is.na(hash_to_file_1$N)] <- 0
flags <- hash_to_file_1 %>%
filter(N ==1) %>%
tidyr::unnest(data) %>%
tidyr::complete(rec2 = unique(hash_to_file_1$rec2)) %>%
select(-N) %>%
setNames(c("rec2", "eligible_patterns", "eligible_records")) %>%
group_split(rec2, .keep = F)
patterns <- list(ohe = unique_patterns,
total_counts = total_counts,
#pattern_counts_by_record = pattern_counts_by_record,
#record_counts_by_pattern = record_counts_by_pattern,
hash_count_list = hash_count_list,
hash_to_file_1 = hash_to_file_1,
flags = flags,
field_marker = field_marker,
n1 = n1,
n2 = n2,
pair_to_pattern = pair_to_pattern)
patterns$hash_count_list
total_counts
P
#total_counts <- rowSums(hash_count_list)
total_counts <- temp %>%
group_by(hash_id, .drop = F) %>%
count() %>%
pull()
devtools::load_all(".")
hash_1 <- hash_comparisons(cd_1, all_patterns = T)
cd_2 <- compare_records(df1, df2[batch_2, ], flds = fields, types = types,
breaks = c(0, .15))
threshold = 1e-6
tmax = 1000
fixed_iterations = NULL
b_init = TRUE
check_every = 10
store_every = check_every
all_patterns = TRUE
df1 <- read.csv("../vablpaper/data/febrl_4_A.csv") %>%
arrange(rec_id) %>%
mutate(rec_id = row_number()) %>%
filter(rec_id <= 10)
df2 <- read.csv("../vablpaper/data/febrl_4_B.csv") %>%
arrange(rec_id) %>%
mutate(rec_id = row_number()) %>%
filter(rec_id <= 10)
batch_1 <- 1:5
batch_2 <- 6:10
n1 <- nrow(df1)
n2 <- nrow(df2)
Z_true <- seq(1:10)
fields <- c(2, 3, 8, 10, 11)
types <- c("lv", "lv","bi", "bi", "bi")
cd_1 <- compare_records(df1, df2[batch_1, ], flds = fields, types = types,
breaks = c(0, .15))
cd <- cd_1
hash_1 <- hash_comparisons(cd_1, all_patterns = T)
cd_2 <- compare_records(df1, df2[batch_2, ], flds = fields, types = types,
breaks = c(0, .15))
hash_2 <- hash_comparisons(cd_2, all_patterns = T)
hash_list <- list(hash_1, hash_2)
hash <- combine_hash(hash_list = hash_list, n1, n2)
out <- vi_efficient(hash)
hash$total_counts
devtools::load_all(".")
out <- vi_efficient(hash)
hash <- hash_comparisons(cd, method = c("vabl", "fabl"))
View(hash)
library(devtools)
use_r("estimate_links_mm")
use_r("evaluate_links_mm")
