sample_with_1(hash_to_file_1[[.y]][[.x]], 1)
})
purrr::imap(z, ~ if(.x == 0) {
return(0)
})
Z.SAMPS[, S]
hash_to_file_1[[1]]
View(hash_to_file_1)
devtools::load_all(".")
n1 <- hash$n1
h2 <- hash$n2
field_marker <- hash$field_marker
unique_patterns <- hash$ohe
pattern_counts <- hash$total_counts
P <- nrow(unique_patterns)
counts_by_rec <- hash$pattern_counts_by_record
hash_to_file_1 <-hash$hash_to_file_1
#candidates_P <- 1:(P+1)
candidates_P <- 0:P
Z.SAMPS <- matrix(NA, nrow = n2, ncol = S)
M.SAMPS <- matrix(NA, nrow = length(field_marker), ncol = S)
U.SAMPS <- matrix(NA, nrow = length(field_marker), ncol = S)
L.SAMPS <- vector(length = S)
PI.SAMPS <- vector(length = S)
Z.temp <- rep(0, n1*n2)
Z <- rep(n1+1, n2)
L <- 0
m <- u <- rep(0, length(field_marker))
matches <- rep(0,P)
#set.seed(1)
# Gibbs
for(s in 1:S){
AZ <- sweep(unique_patterns, MARGIN = 1, STAT = matches, FUN = "*") %>%
colSums() %>%
unname()
nonmatches <- pattern_counts - matches
BZ <- sweep(unique_patterns, MARGIN = 1, STAT = nonmatches, FUN = "*") %>%
colSums() %>%
unname()
m_post <- m_prior + AZ
u_post <- u_prior + BZ
m_post <- split(m_post, field_marker)
m <- as.vector(unlist(sapply(m_post, function(x){
prob <- MCMCpack::rdirichlet(1, x)
prob/sum(prob)
})))
u_post <- split(u_post, field_marker)
u <- as.vector(unlist(sapply(u_post, function(x){
prob <- MCMCpack::rdirichlet(1, x)
prob/sum(prob)
})))
ratio <- (log(m) - log(u)) %>%
rep(., P) %>%
matrix(., nrow = P, byrow = TRUE)
unique_weights <- exp(rowSums(ratio * unique_patterns, na.rm = TRUE))
hash_weights <- lapply(counts_by_rec, function(x){
x * unique_weights
})
pi <- rbeta(1, L + alpha, n2 - L + beta)
Z <- unname(sapply(hash_weights, function(x){
sample(candidates_P, 1, prob = c(1 - pi, x * pi / n1))
}))
#L <- sum(Z < P + 1)
L <- sum(Z > 0)
hash_matches <- factor(Z, levels = 0:P)
df <- data.frame(hash_matches)
matches <- df %>%
group_by(hash_matches, .drop = F) %>%
count() %>%
filter(hash_matches != 0) %>%
pull()
Z.SAMPS[,s] <- Z
M.SAMPS[,s] <- m
U.SAMPS[,s] <- u
L.SAMPS[s] <- L
PI.SAMPS[s] <- pi
if(show_progress){
if (s %% (S / 100) == 0) {
flush.console()
cat("\r", paste("Simulation", ": ", s / (S / 100), "% complete", sep = ""))
}
}
}
S = 50
burn = S * .1
hash_to_file_1[[1]]
hash_list <- vector("list", length(batch_sizes))
for (i in seq_along(batch_sizes)){
cd <- simulate_comparisons(m, u, levels, n1, batch_sizes[i], overlap_vec[i])
hash_list[[i]] <- hash_comparisons(cd, all_patterns = T)
#vi_hash_list[[i]] <- vi_hash_comparisons(cd, all_patterns = T)
print(i)
gc()
}
full_hash <- combine_hash(hash_list = hash_list, n1, n2)
View(full_hash)
out <- gibbs_efficient(full_hash, S=S, burn = burn)
n1 <- hash$n1
h2 <- hash$n2
field_marker <- hash$field_marker
unique_patterns <- hash$ohe
pattern_counts <- hash$total_counts
P <- nrow(unique_patterns)
counts_by_rec <- hash$pattern_counts_by_record
hash_to_file_1 <-hash$hash_to_file_1
#candidates_P <- 1:(P+1)
candidates_P <- 0:P
Z.SAMPS <- matrix(NA, nrow = n2, ncol = S)
M.SAMPS <- matrix(NA, nrow = length(field_marker), ncol = S)
U.SAMPS <- matrix(NA, nrow = length(field_marker), ncol = S)
L.SAMPS <- vector(length = S)
PI.SAMPS <- vector(length = S)
Z.temp <- rep(0, n1*n2)
Z <- rep(n1+1, n2)
L <- 0
m <- u <- rep(0, length(field_marker))
matches <- rep(0,P)
AZ <- sweep(unique_patterns, MARGIN = 1, STAT = matches, FUN = "*") %>%
colSums() %>%
unname()
nonmatches <- pattern_counts - matches
BZ <- sweep(unique_patterns, MARGIN = 1, STAT = nonmatches, FUN = "*") %>%
colSums() %>%
unname()
m_post <- m_prior + AZ
u_post <- u_prior + BZ
m_post <- split(m_post, field_marker)
m <- as.vector(unlist(sapply(m_post, function(x){
prob <- MCMCpack::rdirichlet(1, x)
prob/sum(prob)
})))
u_post <- split(u_post, field_marker)
u <- as.vector(unlist(sapply(u_post, function(x){
prob <- MCMCpack::rdirichlet(1, x)
prob/sum(prob)
})))
ratio <- (log(m) - log(u)) %>%
rep(., P) %>%
matrix(., nrow = P, byrow = TRUE)
unique_weights <- exp(rowSums(ratio * unique_patterns, na.rm = TRUE))
hash_weights <- lapply(counts_by_rec, function(x){
x * unique_weights
})
pi <- rbeta(1, L + alpha, n2 - L + beta)
Z <- unname(sapply(hash_weights, function(x){
sample(candidates_P, 1, prob = c(1 - pi, x * pi / n1))
}))
Z
hash$n2
#L <- sum(Z < P + 1)
L <- sum(Z > 0)
hash_matches <- factor(Z, levels = 0:P)
df <- data.frame(hash_matches)
matches <- df %>%
group_by(hash_matches, .drop = F) %>%
count() %>%
filter(hash_matches != 0) %>%
pull()
S
Z.SAMPS[,s] <- Z
nrow(Z.SAMPS)
length(Z)
s
s = 1
S
Z.SAMPS[,s] <- Z
Z.temp <- rep(0, n1*n2)
Z <- rep(n1+1, n2)
L <- 0
m <- u <- rep(0, length(field_marker))
matches <- rep(0,P)
# Gibbs
for(s in 1:S){
AZ <- sweep(unique_patterns, MARGIN = 1, STAT = matches, FUN = "*") %>%
colSums() %>%
unname()
nonmatches <- pattern_counts - matches
BZ <- sweep(unique_patterns, MARGIN = 1, STAT = nonmatches, FUN = "*") %>%
colSums() %>%
unname()
m_post <- m_prior + AZ
u_post <- u_prior + BZ
m_post <- split(m_post, field_marker)
m <- as.vector(unlist(sapply(m_post, function(x){
prob <- MCMCpack::rdirichlet(1, x)
prob/sum(prob)
})))
u_post <- split(u_post, field_marker)
u <- as.vector(unlist(sapply(u_post, function(x){
prob <- MCMCpack::rdirichlet(1, x)
prob/sum(prob)
})))
ratio <- (log(m) - log(u)) %>%
rep(., P) %>%
matrix(., nrow = P, byrow = TRUE)
unique_weights <- exp(rowSums(ratio * unique_patterns, na.rm = TRUE))
hash_weights <- lapply(counts_by_rec, function(x){
x * unique_weights
})
pi <- rbeta(1, L + alpha, n2 - L + beta)
Z <- unname(sapply(hash_weights, function(x){
sample(candidates_P, 1, prob = c(1 - pi, x * pi / n1))
}))
#L <- sum(Z < P + 1)
L <- sum(Z > 0)
hash_matches <- factor(Z, levels = 0:P)
df <- data.frame(hash_matches)
matches <- df %>%
group_by(hash_matches, .drop = F) %>%
count() %>%
filter(hash_matches != 0) %>%
pull()
Z.SAMPS[,s] <- Z
M.SAMPS[,s] <- m
U.SAMPS[,s] <- u
L.SAMPS[s] <- L
PI.SAMPS[s] <- pi
if(show_progress){
if (s %% (S / 100) == 0) {
flush.console()
cat("\r", paste("Simulation", ": ", s / (S / 100), "% complete", sep = ""))
}
}
}
final_gibbs <- apply(Z.SAMPS, 2, function(z){
purrr::imap(z, ~ if(.x == 0) {
return(0)
} else {
sample_with_1(hash_to_file_1[[.y]][[.x]], 1)
}) %>%
unlist()
})
z <- Z.SAMPS[, S]
purrr::imap(z, ~ if(.x == 0) {
return(0)
}
)
purrr::imap(z, ~ if(.x == 0) {
return(0)
} else {
sample_with_1(hash_to_file_1[[.y]][[.x]], 1)
})
hash_to_file_1[[1]]
hash <- full_hash
View(hash)
n1 <- hash$n1
h2 <- hash$n2
field_marker <- hash$field_marker
unique_patterns <- hash$ohe
pattern_counts <- hash$total_counts
P <- nrow(unique_patterns)
counts_by_rec <- hash$pattern_counts_by_record
hash_to_file_1 <-hash$hash_to_file_1
#candidates_P <- 1:(P+1)
candidates_P <- 0:P
Z.SAMPS <- matrix(NA, nrow = n2, ncol = S)
M.SAMPS <- matrix(NA, nrow = length(field_marker), ncol = S)
U.SAMPS <- matrix(NA, nrow = length(field_marker), ncol = S)
L.SAMPS <- vector(length = S)
PI.SAMPS <- vector(length = S)
Z.temp <- rep(0, n1*n2)
Z <- rep(n1+1, n2)
L <- 0
m <- u <- rep(0, length(field_marker))
matches <- rep(0,P)
# Gibbs
for(s in 1:S){
AZ <- sweep(unique_patterns, MARGIN = 1, STAT = matches, FUN = "*") %>%
colSums() %>%
unname()
nonmatches <- pattern_counts - matches
BZ <- sweep(unique_patterns, MARGIN = 1, STAT = nonmatches, FUN = "*") %>%
colSums() %>%
unname()
m_post <- m_prior + AZ
u_post <- u_prior + BZ
m_post <- split(m_post, field_marker)
m <- as.vector(unlist(sapply(m_post, function(x){
prob <- MCMCpack::rdirichlet(1, x)
prob/sum(prob)
})))
u_post <- split(u_post, field_marker)
u <- as.vector(unlist(sapply(u_post, function(x){
prob <- MCMCpack::rdirichlet(1, x)
prob/sum(prob)
})))
ratio <- (log(m) - log(u)) %>%
rep(., P) %>%
matrix(., nrow = P, byrow = TRUE)
unique_weights <- exp(rowSums(ratio * unique_patterns, na.rm = TRUE))
hash_weights <- lapply(counts_by_rec, function(x){
x * unique_weights
})
pi <- rbeta(1, L + alpha, n2 - L + beta)
Z <- unname(sapply(hash_weights, function(x){
sample(candidates_P, 1, prob = c(1 - pi, x * pi / n1))
}))
#L <- sum(Z < P + 1)
L <- sum(Z > 0)
hash_matches <- factor(Z, levels = 0:P)
df <- data.frame(hash_matches)
matches <- df %>%
group_by(hash_matches, .drop = F) %>%
count() %>%
filter(hash_matches != 0) %>%
pull()
Z.SAMPS[,s] <- Z
M.SAMPS[,s] <- m
U.SAMPS[,s] <- u
L.SAMPS[s] <- L
PI.SAMPS[s] <- pi
if(show_progress){
if (s %% (S / 100) == 0) {
flush.console()
cat("\r", paste("Simulation", ": ", s / (S / 100), "% complete", sep = ""))
}
}
}
Z
n1 <- n2 <- 50
total_overlap <- n2/2
S = 50
burn = S * .1
show_progress <- T
fast = F
R <- NULL
all_patterns <- T
m <- c(.05, .95, .05, .95, .05, .95, .05, .95, .05, .95)
u <- c(.99, .01, .99, .01,
1 - 1/30, 1/30, 1 - 1/12, 1/12, 1 - 1/15, 1/15)
levels <- c(2, 2, 2, 2, 2)
possible_batches <- 1:200
pair_limit = 100000000
pair_limit = 1000
batches <- (n1 * n2 / possible_batches < pair_limit) %>%
which(. == T) %>%
.[1] %>%
possible_batches[.]
normal_batch_size <- n2 %/% batches
last_batch_size <- n2 %% batches
if(last_batch_size == 0){
last_batch_size <- NULL
}
batch_sizes <-c(rep(normal_batch_size, batches), last_batch_size)
batches_with_overlap <- total_overlap %/% normal_batch_size
remaining_overlap <- total_overlap %% normal_batch_size
overlap_vec <- rep(0, length(batch_sizes))
overlap_vec[1:batches_with_overlap] <- normal_batch_size
overlap_vec[batches_with_overlap + 1] <- remaining_overlap
hash_list <- vector("list", length(batch_sizes))
#vi_list <- vector("list", length(batch_sizes))
for (i in seq_along(batch_sizes)){
cd <- simulate_comparisons(m, u, levels, n1, batch_sizes[i], overlap_vec[i])
hash_list[[i]] <- hash_comparisons(cd, all_patterns = T)
#vi_hash_list[[i]] <- vi_hash_comparisons(cd, all_patterns = T)
print(i)
gc()
}
hash <- combine_hash(hash_list = hash_list, n1, n2)
out <- gibbs_efficient(hash, S=S, burn = burn)
result <- estimate_links(out, resolve = F)
result <- estimate_links(out)
result <- estimate_links(out$Z)
result <- estimate_links(out$Z, n1)
out$Z
Z_samps <- out$Z
# temporarily replace all nonlink labels by n1+1
Z_samps[Z_samps > n1+1] <- n1+1
# temporarily replace all nonlink labels by n1+1
#Z_samps[Z_samps > n1+1] <- n1+1
tableLabels <- apply(Z_samps, 1, tabulate, nbins=max(Z_samps))
tableLabels
tableLabels <- tableLabels/ncol(Z_samps)
tableLabels
View(tableLabels)
dim(out$Z)
devtools::load_all(".")
out <- gibbs_efficient(hash, S=S, burn = burn)
result <- estimate_links(out$Z, n1)
result$Z_hat
out <- vi_efficient(hash)
result <- vi_estimate_links(out, hash, resolve = F)
View(hash)
total_counts <- Reduce(`+`, purrr::map(hash_list, ~.x$total_counts))
pattern_counts_by_record <- hash_list %>%
purrr::map(`[[`, "pattern_counts_by_record") %>%
purrr::flatten()
hash_to_file_1 <- hash_list %>%
purrr::map(`[[`, "hash_to_file_1") %>%
purrr::flatten()
record_counts_by_pattern <- purrr::transpose(pattern_counts_by_record) %>%
purrr::map(unlist) %>%
purrr::map(unname)
hash_list[[1]]$flags
devtools::load_all(".")
for (i in seq_along(batch_sizes)){
cd <- simulate_comparisons(m, u, levels, n1, batch_sizes[i], overlap_vec[i])
hash_list[[i]] <- hash_comparisons(cd, all_patterns = T)
#vi_hash_list[[i]] <- vi_hash_comparisons(cd, all_patterns = T)
print(i)
gc()
}
hash <- combine_hash(hash_list = hash_list, n1, n2)
hash$flags
out <- vi_efficient(hash)
result <- vi_estimate_links(out, hash, resolve = F)
result$Zhat
out$t
n2 <- hash$n2
pattern_probs <- lapply(1:n2, function(j){
out$pattern_weights/out$C[j]
})
pattern_probs[[4]]
possible_records <- lapply(1:n2, function(j){
record <- c(hash$flags[[j]]$eligible_records, 0)
prob <- c(pattern_probs[[j]][hash$flags[[j]]$eligible_patterns],
exp(digamma(out$b_pi)) / out$C[j])
data.frame(record, prob)
})
possible_records[[4]]
devtools::load_all(".")
result <- vi_estimate_links(out, hash, resolve = F)
View(result$Zhat)
result$Zhat
Z_true <- rep(0, n2)
Z_true[1:total_overlap] <- 1:total_overlap
eval <- evaluate_links(result$Zhat, Z_true, n1)
ptm <- proc.time()
out <- gibbs_efficient(hash, S=S, burn = burn)
result <- estimate_links(out$Z, n1)
#eval <- evaluate_links(result$Zhat, Z_true, n1)
seconds <- (proc.time() - ptm)[3]
fabl_df <- data.frame(n1 = n1,
time = seconds,
iterations = S,
method = "fabl")
ptm <- proc.time()
out <- vi_efficient(hash)
result <- vi_estimate_links(out, hash, resolve = F)
seconds <- (proc.time() - ptm)[3]
vabl_df <- data.frame(n1 = n1,
time = seconds,
iterations = out$t,
method = "vabl")
df <- rbind(fabl_df, vabl_df)
df
# k = as.integer(Sys.getenv("SLURM_ARRAY_TASK_ID"))
# n1_seq <- seq(5000, by = 5000, length.out = 20)
# n1 <- n1_seq[k]
# n2 <- n1
n1 <- n2 <- 50
total_overlap <- n2/2
S = 50
burn = S * .1
Z_true <- rep(0, n2)
Z_true[1:total_overlap] <- 1:total_overlap
show_progress <- T
fast = F
R <- NULL
all_patterns <- T
m <- c(.05, .95, .05, .95, .05, .95, .05, .95, .05, .95)
u <- c(.99, .01, .99, .01,
1 - 1/30, 1/30, 1 - 1/12, 1/12, 1 - 1/15, 1/15)
levels <- c(2, 2, 2, 2, 2)
possible_batches <- 1:200
pair_limit = 100000000
pair_limit = 1000
batches <- (n1 * n2 / possible_batches < pair_limit) %>%
which(. == T) %>%
.[1] %>%
possible_batches[.]
normal_batch_size <- n2 %/% batches
last_batch_size <- n2 %% batches
if(last_batch_size == 0){
last_batch_size <- NULL
}
batch_sizes <-c(rep(normal_batch_size, batches), last_batch_size)
batches_with_overlap <- total_overlap %/% normal_batch_size
remaining_overlap <- total_overlap %% normal_batch_size
overlap_vec <- rep(0, length(batch_sizes))
overlap_vec[1:batches_with_overlap] <- normal_batch_size
overlap_vec[batches_with_overlap + 1] <- remaining_overlap
hash_list <- vector("list", length(batch_sizes))
#vi_list <- vector("list", length(batch_sizes))
for (i in seq_along(batch_sizes)){
cd <- simulate_comparisons(m, u, levels, n1, batch_sizes[i], overlap_vec[i])
hash_list[[i]] <- hash_comparisons(cd, all_patterns = T)
#vi_hash_list[[i]] <- vi_hash_comparisons(cd, all_patterns = T)
print(i)
gc()
}
hash <- combine_hash(hash_list = hash_list, n1, n2)
ptm <- proc.time()
out <- gibbs_efficient(hash, S=S, burn = burn)
seconds <- (proc.time() - ptm)[3]
result <- estimate_links(out$Z, n1)
#eval <- evaluate_links(result$Zhat, Z_true, n1)
fabl_df <- data.frame(n1 = n1,
time = seconds,
iterations = S,
method = "fabl")
ptm <- proc.time()
out <- vi_efficient(hash)
seconds <- (proc.time() - ptm)[3]
result <- vi_estimate_links(out, hash, resolve = F)
vabl_df <- data.frame(n1 = n1,
time = seconds,
iterations = out$t,
method = "vabl")
df <- rbind(fabl_df, vabl_df)
saveRDS(df, glue("out/speed_sim_big/n_{k}")
df
